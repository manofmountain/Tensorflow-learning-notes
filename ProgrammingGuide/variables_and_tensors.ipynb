{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train a model, we use variables to hold and update parameters. Variables are in-memory buffers containing tensors. They must be explicitly initialized and can be saved to disk during and after training. Also we can later restore saved values to exercise or analyze the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create two variables\n",
    "#Calling tf.Variable() adds several ops to graph\n",
    "#a. A variable op that holds the variable value;\n",
    "#b. An initializer op that sets the variable to its initial value. Actually a tf.assign op;\n",
    "#c. The ops for the initial value, such as the zeros op for the biases\n",
    "weights = tf.Variable(tf.random_normal([784,200], stddev=0.35), name=\"weights\")\n",
    "biases = tf.Variable(tf.zeros([200]), name=\"biases\")\n",
    "\n",
    "\n",
    "#Device placement\n",
    "#A variable can be pinned to a particular device when it's created by using tf.device(...): block\n",
    "#\n",
    "#Pin a variable to a cpu\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    cpuV0 = tf.Variable(tf.zeros([10]), name=\"cpuV0\")\n",
    "\n",
    "#with tf.device(\"/cpu:0\"):\n",
    "    cpuV1 = tf.Variable(tf.zeros([5]), name=\"cpuV1\")\n",
    "#with tf.device(\"/gpu:0\"):\n",
    "#    gpuV = tf.Variable(tf.ones([5]), name=\"gpuV\")\n",
    "\n",
    "#with tf.device(\"/job:ps/task:7\"):\n",
    "#    v = tf.Variable(...)\n",
    "\n",
    "##Notes: Operations that mutate a variable, such as tf.Variable.assign and the parameter update operations in a\n",
    "#tf.train.Optimizer must run on the same device as the variable. Incompatible device placement directives will\n",
    "#be ignored when creating these operations.\n",
    "\n",
    "#Device placement is important when running in a replicated setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: /localdisk/tmp/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /localdisk/tmp/model.ckpt\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "#Initialization\n",
    "#Variable initializers must be run explicitly before other ops in our model can be run. \n",
    "#We can also alternatively restore variable values from a checkpoint file\n",
    "\n",
    "#Add an op to initialize the variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "#Later, when launching the model\n",
    "#sess = tf.Session()\n",
    "with tf.Session() as sess:\n",
    "    #Run the init ops\n",
    "    sess.run(init_op)\n",
    "\n",
    "    \n",
    "    save_path = saver.save(sess, \"/localdisk/tmp/model.ckpt\")\n",
    "    print \"Model saved in file: %s\" % save_path\n",
    "    saver.restore(sess, \"/localdisk/tmp/model.ckpt\")\n",
    "    print \"Model restored.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF programs use a tensor data structure to represent all data. We can think of it as an n-dimensional array or list. A tensor has a static type and dynamic dimensions. Only tensors may be passed between nodes in the computational graph.\n",
    "Tensors are described by a unit of dimensionality known as rank. It is the number of dimensions of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n",
      "[1.1, 2.2, 3.3]\n",
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "[[[2], [4], [6]], [[8], [10], [12]], [[14], [16], [18]]]\n"
     ]
    }
   ],
   "source": [
    "# a scalar : rank 0\n",
    "s = 483\n",
    "print s\n",
    "# vector : rank 1\n",
    "v = [1.1, 2.2, 3.3]\n",
    "print v\n",
    "# matrix : rank 2\n",
    "m = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "print m\n",
    "# 3-Tensor : rank 3\n",
    "t = [[[2], [4], [6]], [[8],[10], [12]], [[14], [16], [18]]]\n",
    "print t\n",
    "# n-Tensor : rank n...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf uses three notational conventions to describe tensor dimensionality: rank, shape and dimension number.\n",
    "Shapes can be represented via python lists / tuples of ints, or with the tf.TensorShape.\n",
    "In addition to dimensionality, tensors have a data type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
